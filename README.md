# Weather DataÂ Pipeline Project  
<sub>ApacheÂ AirflowÂ â€¢ ApacheÂ SparkÂ â€¢ PostgreSQLÂ â€¢ DockerÂ Compose</sub>

![Architecture diagram](diagrams/weather-pipeline.png)

---

## ğŸ¯Â AmaÃ§
OpenWeather APIâ€™sinden saatlik hava durumu verilerini Ã§ekip:
1.Â SparkÂ Ã¼zerinde iÅŸleyerek dÃ¶nÃ¼ÅŸtÃ¼rmek,
2.Â PostgreSQL veritabanÄ±na yÃ¼klemek,
3.Â TÃ¼m sÃ¼reci Airflow DAGâ€™Ä±yla orkestre etmek.

Projeyi **DockerÂ Compose** ile tek komutla ayaÄŸa kaldÄ±rabilir; Portainer & pgAdmin ile yÃ¶netebilirsiniz.

---

## ğŸ“‚Â Dizin YapÄ±sÄ±
```
â”œâ”€â”€ dags/                     # Airflow DAG dosyalarÄ±
â”‚Â Â  â””â”€â”€ weather_etl.py
â”œâ”€â”€ spark-app/                # Spark uygulamasÄ± & submit script
â”‚Â Â  â”œâ”€â”€ weather_transform.py
â”‚Â Â  â””â”€â”€ weather-submit
â”œâ”€â”€ postgres/
â”‚Â Â  â””â”€â”€ init.sql              # BaÅŸlangÄ±Ã§ ÅŸemasÄ± & tablo oluÅŸturma
â”œâ”€â”€ diagrams/
â”‚Â Â  â””â”€â”€ weather-pipeline.png  # Mimari diyagram
â”œâ”€â”€ Dockerfile                # Airflow imageâ€™i iÃ§in
â”œâ”€â”€ docker-compose.yaml       # TÃ¼m servis tanÄ±mlarÄ±
â””â”€â”€ README.md
```

---

## ğŸš€Â HÄ±zlÄ± BaÅŸlangÄ±Ã§
```bash
# 1) Projeyi klonla & klasÃ¶re gir
$ git clone https://github.com/eqselans/weather-data-pipeline weather-pipeline && cd weather-pipeline

# 2) Ortam deÄŸiÅŸkenlerini ayarla
# .env iÃ§inde WEATHER_API_KEY vb. deÄŸerleri doldur

# 3) Servisleri baÅŸlat
$ docker compose up -d --build

# 4) Airflow UI (localhost:8080) -> admin / admin
#    Portainer   (localhost:9000)
#    pgAdmin     (localhost:5050) -> pgadmin@example.com / admin

# 5) Airflow Scheduler servisini baÅŸlat
$ airflow scheduler 
```

### ServisÂ PortlarÄ±
| Servis | Port |
|--------|------|
| Airflow Web UI | **8080** |
| Spark Master UI | **8088** |
| Spark Worker UI | **8089** |
| PostgreSQL | **5432** |
| pgAdmin | **5050** |
| Portainer | **9000** |

---

## âš™ï¸Â Airflow
* **Executor:** `LocalExecutor`
* **DeÄŸiÅŸkenler:**
  * `OPENWEATHER_API_KEY` â€“ UIÂ > AdminÂ > Variables veya `scripts/load_airflow_vars.py` ile CLIâ€™dan yÃ¼kleyin.
* **DAG:** `weather_api_spark_etl`
  * `BashOperator` â†’ `spark-master` containerâ€™Ä±nda `weather-submit.sh` Ã§aÄŸrÄ±lÄ±r
  * BaÅŸarÄ±sÄ±z olursa otomatik yeniden dener; loglar `./logs` volumeâ€™unda saklanÄ±r

---

## ğŸ”¥Â Spark UygulamasÄ±
* `weather_transform.py`Â â†’ JSON verilerini DataFrameâ€™e Ã§evirir, kolon tiplerini dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r, timestamp ekler.
* `spark-submit` parametreleri `weather-submit` iÃ§inde tanÄ±mlÄ±:
  * `--master spark://spark-master:7077`
  * Maven paketi: `org.postgresql:postgresql:42.7.3`
* Ortam deÄŸiÅŸkeni `WEATHER_API_KEY` Spark driverâ€™a `docker exec -e` ile iletilir.

---

## ğŸ˜Â PostgreSQL
BaÅŸlangÄ±Ã§ tablosu **`weather_data`**
```sql
CREATE TABLE IF NOT EXISTS weather_data (
  city         TEXT,
  condition    TEXT,
  temperature  DOUBLE PRECISION,
  humidity     INTEGER,
  pressure     INTEGER,
  timestamp    TIMESTAMP
);
```
pgAdmin ile tabloyu gÃ¶rÃ¼ntÃ¼leyebilir veya sorgulayabilirsiniz.

---

## ğŸ› ï¸Â GeliÅŸtirme
* **PythonÂ 3.9**  
  - Kod stiliÂ : `black`, `isort`, `flake8`Â â†’ `pre-commit` hookâ€™larÄ± hazÄ±r.
* **Conventional Commits** kullanÄ±n (Ã¶rn. `feat:`, `fix:`, `docs:`).  
* Yeni bir Ã¶zellik iÃ§in `feature/<isim>` dalÄ± aÃ§Ä±n, PR ile birleÅŸtirin.

---

## ğŸ“‹Â SÄ±k KullanÄ±lan Komutlar
| Ä°ÅŸlem | Komut |
|-------|-------|
| TÃ¼m servisleri durdur | `docker compose stop` |
| Yeniden baÅŸlat | `docker compose start` |
| LoglarÄ± takip | `docker compose logs -f airflow` |
| Airflow scheduler shell | `docker compose exec airflow airflow scheduler` |
| Spark shell | `docker compose exec spark-master spark-shell` |

> **Duraklat/Devam (Stop/Start) Notu**  
> Volumeâ€™ler kalÄ±cÄ± olduÄŸu iÃ§in konteynerleri kapatÄ±p ( `docker compose stop` ) uzun sÃ¼re sonra `start` yaptÄ±ÄŸÄ±nÄ±zda veritabanÄ± ve Airflow metadatasÄ± korunur. YalnÄ±zca versiyon gÃ¼ncellemesi yapacaksanÄ±z `docker compose pull` + `up -d --build` Ã¶ncesinde `db upgrade` komutu Ã§alÄ±ÅŸtÄ±rmanÄ±z yeterlidir.

---


